{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 5\n",
    "*Author: Puri Rudick*\n",
    "\n",
    "##### 1. Compile a list of static links (permalinks) to individual user movie reviews from one particular website. This will be your working dataset for this assignment, as well as for assignments 7 and 8.   \n",
    "- It does not matter if you use a crawler or if you manually collect the links, but you will need at least 100 movie review links. Note that, as of this writing, the robots.txt file of IMDB.com allows the crawling of user reviews.\n",
    "- Each link should be to a web page that has only one user review of only one movie, e.g., the user review permalinks on the IMDB site.\n",
    "- Choose reviews of movies that are all in the same genre, e.g., sci-fi, mystery, romance, superhero, etc.  \n",
    "- Make sure your collection includes reviews of several movies in your chosen genre and that it includes a mix of negative and positive reviews.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.corpus import brown\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### 2. Extract noun phrase (NP) chunks from your reviews using the following procedure:\n",
    "- In Python, use BeautifulSoup to grab the main review text from each link.  \n",
    "- Next run each review text through a tokenizer, and then try to NP-chunk it with a shallow parser. \n",
    "- You probably will have too many unknown words, owing to proper names of characters, actors, and so on that are not in your working dictionary. Make sure the main names that are relevant to the movies in your collection of reviews are added to the working lexicon, and then run the NP chunker again.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### 3. Output all the chunks in a single list for each review, and submit that output for this assignment. Also submit a brief written summary of what you did (describe your selection of genre, your source of reviews, how many you collected, and by what means).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My news sentence is from this [link](https://www.nbcnews.com/tech/internet/internet-explorers-run-finally-comes-end-rcna33628 \"Title\"). It talks about how Microsoft Edge will completely replace Internet Explorer.\n",
    "\n",
    "My manual tagging will be:\n",
    "'As':IN, 'of':IN, 'Wednesday':NNP, 'Microsoft':NNP, 'will':MD, 'no':RB, 'longer':RBR, 'support':VB, 'the':DT, 'once':RB, 'dominant':JJ 'browser':NN, 'that':WDT, 'legions':NNS, 'of':IN, 'web':NN, 'surfers':NNS, 'loved':VBD, 'to':TO, 'hate':VB, 'and':CC, 'a':DT, 'few':JJ, 'still':RB, 'claim':VBP, 'to':TO, 'adore':VB\n",
    "\n",
    "The pos_tag and spaCy taggers did a good job for tagging this sentence. The results from both are relatively the same as what I, a human, tagged. The UnigramTagger did a poor job on this sentence. As you can see that some words like 'Microsoft', 'browser', and 'surfers' do not get any tags. I'm not sure if these words are considered as quite new words since they started to be used after internet has become popular."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('puri')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d692d47bc7c3fd9ec535c01abc8074d7158d61b58c9ea9d669c449a37d28f90a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
